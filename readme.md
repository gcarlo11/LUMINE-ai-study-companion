# üìö LUMINE: Adaptive Study Companion

**Your intelligent AI-powered study partner, designed to help you understand and learn from your documents.**

[![Next.js](https://img.shields.io/badge/Next.js-000000?style=for-the-badge&logo=nextdotjs&logoColor=white)](https://nextjs.org/) [![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com/) [![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/) [![TypeScript](https://img.shields.io/badge/TypeScript-3178C6?style=for-the-badge&logo=typescript&logoColor=white)](https://www.typescriptlang.org/) [![Tailwind CSS](https://img.shields.io/badge/Tailwind_CSS-38B2AC?style=for-the-badge&logo=tailwind-css&logoColor=white)](https://tailwindcss.com/)

---

## ‚ú® Overview

<p align="left">
  <img src="images/Screenshot 1.png" alt="Preview 1" width="300"/>
  <img src="images/Screenshot 2.png" alt="Preview 2" width="300"/>
</p
<p align="left">
  <img src="images/Screenshot 3.png" alt="Preview 3" width="300"/>
  <img src="images/Screenshot 4.png" alt="Preview 4" width="300"/>
</p>


Adaptive Study Companion is a web application that leverages the power of Large Language Models (LLMs) to provide an interactive and adaptive learning experience. Simply upload your PDF documents (lecture notes, articles, textbooks), and the AI assistant will help you understand the content, answer your questions, and provide summaries based *specifically* on the uploaded material.

The sleek and modern interface, built with Next.js and styled with Tailwind CSS & Shadcn UI, offers a seamless chat experience powered by a robust FastAPI backend.

---

## üöÄ Key Features

* **üìÑ PDF Upload & Processing:** Easily upload your study materials in PDF format.
* **üß† AI-Powered Q&A:** Ask questions about the content of your uploaded documents and receive context-aware answers generated by Google's Gemini model.
* **üîç Contextual Understanding:** The AI utilizes Retrieval-Augmented Generation (RAG) with FAISS vector indexing to ensure answers are based *solely* on the provided document.
* **üí¨ Interactive Chat Interface:** A smooth, responsive chat UI built with modern frontend technologies (Next.js, Tailwind, Framer Motion).
* **üí® Fast & Efficient Backend:** Powered by FastAPI for high performance.
* **üîí Ephemeral Data:** Uploaded document data (text, chunks, embeddings) is processed and stored only in memory for the current session, ensuring privacy and automatic cleanup upon server restart.

---

## üõ†Ô∏è Tech Stack

* **Frontend:**
    * Framework: [Next.js](https://nextjs.org/) (React)
    * Language: [TypeScript](https://www.typescriptlang.org/)
    * Styling: [Tailwind CSS](https://tailwindcss.com/)
    * UI Components: [Shadcn UI](https://ui.shadcn.com/)
    * Animation: [Framer Motion](https://www.framer.com/motion/)
    * Markdown Rendering: [react-markdown](https://github.com/remarkjs/react-markdown)
* **Backend:**
    * Framework: [FastAPI](https://fastapi.tiangolo.com/)
    * Language: [Python](https://www.python.org/)
    * PDF Parsing: [pdfplumber](https://github.com/jsvine/pdfplumber)
    * Embeddings: [Sentence Transformers](https://www.sbert.net/) (`all-MiniLM-L6-v2`)
    * Vector Indexing: [FAISS](https://github.com/facebookresearch/faiss) (Facebook AI Similarity Search)
    * LLM Integration: [Google Generative AI (Gemini)](https://ai.google.dev/)
* **Environment Management:**
    * [Poetry](https://python-poetry.org/) (Recommended for backend Python) or `venv`
    * [npm](https://www.npmjs.com/)/[yarn](https://yarnpkg.com/)/[pnpm](https://pnpm.io/) (for frontend Node.js)

---

## ‚öôÔ∏è Getting Started

### Prerequisites

* Node.js (v18 or later recommended)
* Python (v3.10 or later recommended)
* `pip` and `venv` (or your preferred Python package manager like Poetry)
* A Google AI API Key for Gemini (set as an environment variable)

### Installation & Setup

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/your-username/adaptive-study-companion.git](https://github.com/your-username/adaptive-study-companion.git)
    cd adaptive-study-companion
    ```

2.  **Backend Setup:**
    * Navigate to the `backend` directory:
        ```bash
        cd backend
        ```
    * Create and activate a virtual environment:
        ```bash
        python -m venv venv
        source venv/bin/activate  # On Windows use `venv\Scripts\activate`
        ```
    * Install Python dependencies:
        ```bash
        pip install -r requirements.txt
        ```
    * Create a `.env` file in the `backend` directory and add your Google AI API Key:
        ```env
        # backend/.env
        GEMINI_API_KEY=YOUR_GEMINI_API_KEY_HERE
        ```

3.  **Frontend Setup:**
    * Navigate to the `frontend` directory:
        ```bash
        cd ../frontend
        ```
    * Install Node.js dependencies:
        ```bash
        npm install
        # or yarn install or pnpm install
        ```

### Running the Application

1.  **Start the Backend Server:**
    * In your terminal (make sure you are in the `backend` directory and the virtual environment is active):
        ```bash
        uvicorn app.main:app --reload
        ```
    * The backend will be running at `http://127.0.0.1:8000`.

2.  **Start the Frontend Development Server:**
    * Open a *new* terminal, navigate to the `frontend` directory:
        ```bash
        cd ../frontend
        ```
    * Run the development server:
        ```bash
        npm run dev
        # or yarn dev or pnpm dev
        ```
    * Open [http://localhost:3000](http://localhost:3000) in your browser.

---

## üìñ Usage

1.  **Open the Application:** Navigate to `http://localhost:3000`.
2.  **Upload a PDF:** Click the upload button (üîó icon) and select a PDF document you want to study. The backend will process it.
3.  **Ask Questions:** Once the file is processed, type your questions about the document content into the chat input and press Send.
4.  **Receive Answers:** The AI will generate answers based *only* on the information present in the uploaded PDF.
5.  **New Document/Session:** Uploading a new PDF will replace the previous document's context in the backend's memory. Restarting the backend server will also clear the memory.
